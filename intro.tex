% What problem are you going to solve.

The National Strategic Computing Initiative (NSCI \cite{NSCI}) puts forth a critical
problem as we move to exascale: {\em ``Increasing coherence between the technology base used for 
modeling and simulation and that used for data analytic computing.''}  
A key challenge lies in providing statistical analysis and machine learning 
tools that are simple and efficient.
Simple tools need to be programmable, interactive, and extensible, 
allowing scientists to encode and deploy complex algorithms. 
Successful examples include R, SciPy, and Matlab.  Efficiency dictates that tools should 
leverage modern HPC architectures, including scalable parallelism, high-speed networking,
and fast I/O from memory and solid-state storage.


%In today's big data era, we face the challenges in both the explosion of
%data volume and the increasing complexity of data analysis. Experiments,
%simulations and observations generate terabytes or
%even petabytes in many scientific and business areas. After collecting
%a massive amount of data, we often need to perform complex data analysis
%and machine learning techniques to extract value from the data. To handle
%the increasing volume size and effectively extract value from the data,
%the field of data mining and machine learning evolves rapidly and the community
%is developing many new algorithms to process large datasets.

% How have others addressed the problem?

Large-scale data analysis requires a large parallel machine or a cluster to
gain computation power and memory capacity. Currently,
there are two approaches of implementing parallel algorithms to process large
datasets. One can write an efficient implementation with low-level parallel
primitives such as the ones provided by MPI \cite{mpi} or OpenMP \cite{openmp}.
This approach requires expertise in parallel programming and significant
effort from programmers. The other approach is to use high-level programming
frameworks that provide high-level operations to reduce the burden of
programmers. In general, the second approach is less computationally
efficient but can significantly increase productivity and lower the barrier
of writing parallel implementations. The second approach is 
preferred in the rapidly evolving fields of machine learning and data mining.
%The high-level programming interface enables non-expert programmers
%to effectively use computation resources.

% Why is it hard?

It is challenging to provide a programming framework that has a high-level
programming interface and achieves both generality and efficiency.
Some highly-optimized linear algebra libraries \cite{mkl, openblas, elemental,
trilinos, petsc} provides a matrix programming interface that has a limited
set of matrix operations with efficient implementations, e.g.~BLAS provides
only matrix multiplication and not integer operations or row/column operations.
Users have to parallelize the remaining matrix
operations themselves that are not supported by the libraries. 
High-level programming frameworks, such as R and Matlab, provide a
general programming interface for users to express varieties of algorithms, but
do not produce efficient parallel code.

% What is the nature of your solution?
%Matrix operations are an intuitive formulation for many computation tasks,
%especially for many data analysis tasks. For example, we can store samples
%collected from an experiment in a matrix with rows corresponding to samples
%and columns corresponding to attributes.
%Consequently, we express the computation on the data matrix with a sequence
%of matrix operations. Such a formulation simplifies the implementation of
%data analysis algorithms and is very intuitive for many machine learning
%and data analysis experts.

We present FlashMatrix, a programming framework that provides a high-level
matrix-oriented functional programming interface and supports automatic
parallelization and out-of-core execution for large-scale data analysis.
Unlike most of the linear algebra libraries, FlashMatrix provides a small
set of highly-optimized generalized matrix operations (GenOps) to achieve
generality. It reimplements many matrix operations in the R \textit{base}
package with GenOps to execute R code in parallel and
out of core automatically. FlashMatrix focuses on optimizations in
a single machine and scales matrix operations beyond memory capacity by utilizing
solid-state drives (SSDs). This design choice conforms with a current trend of
hardware design that scales up a single machine for high performance computing
\cite{Ang14}, including analysis of data stored on SSDs of I/O burst buffers
\cite{burst}.
% bb = https://scholar.google.com/scholar?cluster=13235278116505344242&hl=en&as_sdt=0,21&sciodt=0,21

%These machines typically have multiple processors with many CPU cores and
%a large amount of memory. They are also equipped with fast flash
%memory such as solid-state drives (SSDs) to further extend memory capacity.
%This conforms to the node design for supercomputers \cite{Ang14}.

% Why is it new/different/special?

We overcome many technical challenges to move data from SSDs to CPU efficiently,
overcoming the large speed disparity between CPU and memory, as well as between
memory and
SSDs. The speed disparity of CPU and DRAM has increased exponentially over
the past decades \cite{Wilkes01}. While SSDs have high IOPS and sequential
I/O throughput, they are still an order of magnitude slower than DRAM.
To the contrary, many data analysis tasks are data-intensive. Matrix
formulation further increases data movement between CPU and SSDs because
a matrix computation framework typically performs an operation
on the entire input matrices before moving to the next operation.
% As such,
%the performance of the data analysis tasks is usually limited by memory
%bandwidth instead of computing power.

Another challenge in FlashMatrix is to reduce computation overhead. A GenOp in
FlashMatrix takes some functions as additional arguments that define operations
on individual elements in the input matrices. To support the matrix operations
in the R \textit{base} package, a GenOp accepts functions at run time.
As such, each operation on an element potentially results in a function call,
causing significant computation overhead.

To move data efficiently, FlashMatrix evaluates expressions lazily and fuses
operations aggressively in a single parallel execution job.
FlashMatrix builds a directed acyclic graph (DAG) to represent all operations
in a single execution. When evaluating the computation in a DAG, FlashMatrix
performs two levels of matrix partitioning to improve data utilization in
memory hierarchy and reduce data movement between memory and SSDs
as well as between CPU and memory. To access data stored on SSDs, FlashMatrix
streams data from SSDs to yield maximal I/O throughput.

%\dz{maybe we should say something about optimization on memory allocation?}

To reduce computation overhead, we deploy vectorized user-defined
functions (VUDFs), which operates on a vector of elements instead of
an individual element. We define multiple forms for each VUDF and automatically
select the right form for each GenOp to amortize the function call overhead.
When invoking VUDFs, GenOps choose the right vector length to balance
the amortization of the function call overhead and CPU cache misses.
Inside VUDFs, we use vector CPU instructions, such as AVX \cite{avx},
to further improve performance.

% What are it's key features?

We implement multiple machine learning algorithms such as KMeans \cite{kmeans}
and Gaussian Mixture Model \cite{gmm} in FlashMatrix with its R programming
interface to benchmark its performance. On a large parallel machine with 48
CPU cores and fast SSDs, the out-of-core execution of these R implementations
in FlashMatrix achieves performance comparable to the in-memory execution
while significantly outperforming the ones in Spark MLlib \cite{spark}.
When running in a single thread, the R implementations outperform the C and
FORTRAN implementations in the R framework. In addition, FlashMatrix achieves
almost linear speedup in a multicore NUMA machine for all of the algorithms.
We believe FlashMatrix significantly lowers the requirements for writing parallel
and scalable implementations of data analysis algorithms; it also offers new
design possibilities for data analysis clusters, replacing memory with larger
and cheaper SSDs and processing bigger problems on fewer nodes.
