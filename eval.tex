\section{Experimental evaluation}
We evaluate the performance of FlashMatrix with statistics and machine learning
applications both in memory and on SSDs. We compare their
performance with the implementations in Spark MLlib \cite{mllib},
a high-optimized parallel machine learning library. We further
illustrate the effectiveness of the optimizations deployed in FlashMatrix
when running both in memory and on SSDs.

We conduct experiments on a non-uniform memory architecture machine with
four Intel Xeon E7-4860 processors, clocked at 2.6 GHz, and 1TB memory of
DDR3-1600. Each processor has 12 cores. The machine has three LSI SAS 9300-8e
host bus adapters (HBA) connected to a SuperMicro storage chassis, in which
24 OCZ Intrepid 3000 SSDs are installed. The 24 SSDs together are capable of
delivering 12 GB/s for read and 10 GB/s for write at maximum. The machine runs
Linux kernel v3.13.0. We use 48 threads for both in-memory and out-of-core
execution of FlashMatrix as well as Spark.

\subsection{Statistics and Machine learning applications} \label{sec:apps}
We implement multiple important applications in the field of statistics and
machine learning. These applications are implemented completely with R and
rely on FlashMatrix to perform computation in parallel and out of core.
\begin{itemize}
	\item Multivariant statistical summary: this computes minimum, maximum,
		mean, L1 norm, L2 norm, the number of non-zero values and variance
		of each random variable for a given set of observations.
	\item Correlation: this computes Pearson's correlation \cite{} between
		two series of observations and is commonly used in statistics.
	\item Singular value decomposition (SVD) factorizes a matrix into
		three matrices: $U$, $\Sigma$ and $V$ such that $A=U \Sigma V^T$, where
		both $U$ and $V$ are orthonormal matrices and $\Sigma$ is a diagonal
		matrix with non-negative diagonals in descending order. SVD is commonly
		used for dimension reduction.
	\item KMeans \cite{kmeans} is an iterative algorithm of partitioning a set
		of observations into $k$ clusters
		so that each data point belongs to the cluster with minimal mean. KMeans
		is one of the most popular clustering algorithms and is identified as
		one of the top 10 data mining algorithms \cite{top10}.
	\item Gaussian Mixture Model (GMM) \cite{gmm} is an iterative clustering
		algorithm that assumes observations are sampled from a mixture of
		Gaussian distributions and use expectation maximization (EM) \cite{gmm}
		algorithm to fit the model. This algorithm is also identified as one
		of the top 10 data mining algorithms \cite{top10}.
\end{itemize}

The algorithms have various computation complexity but have the same I/O
complexity (Table \ref{tbl:algs}). Computing statistical summary
has the lowest computation complexity, while GMM has the highest asymptotic
computation complexity. The first three applications require to read the entire
dataset once to perform computation and each iteration of KMeans requires to
read the entire dataset once. Despite lazy evalution, the FlashMatrix
implementation of GMM requires to read the dataset multiple times and write
intermediate data in each iteration.

\begin{table}
\begin{center}
\footnotesize
\begin{tabular}{|c|c|c|c|c|}
\hline
Application & Computation & I/O \\
\hline
Summary & $O(n \times p)$ & $O(n \times p)$ \\
\hline
Correlation & $O(n \times p^2)$ & $O(n \times p)$ \\
\hline
SVD & $O(n \times p^2)$ & $O(n \times p)$ \\
\hline
KMeans (1 iteration) & $O(n \times p \times k)$ & $O(n \times p)$ \\
\hline
GMM (1 iteration) & $O(n \times p^2 \times k)$ & $O(n \times p + n \times k)$ \\
\hline
\end{tabular}
\normalsize
\end{center}
\caption{The computation and I/O complexity of the algorithms for the five
	applications. $n$ is the number of data points in the dataset, $p$ is
	the number of the features and $k$ is the number of clusters KMeans and
GMM partition the dataset.}
\label{tbl:algs}
\end{table}

KMeans and GMM typically run on a dataset with a small number of features
due to curse of dimensionality while the other applications may be applied
to datasets with various numbers
of features. For performance evaluation, we run KMeans and GMM on a matrix
with 65 million rows and 32 columns, constructed from 32 eigenvectors from
the Friendster graph \cite{friendster}. Running KMeans on eigenvectors is
an important step of spectral clustering \cite{Luxburg07} to partition vertices
to clusters. We measure the performance of the other three applications on
random matrices with 65 million rows and vary the number of columns from 8
to 512.

\subsection{Performance of FlashMatrix in memory and on SSDs}

We compare the in-memory and external-memory performance of the FlashMatrix
implementations of the applications thoroughly with different datasets and
different parameters. We run the first three applications on datasets with
the number of features varying from 8 to 512. For KMeans and GMM, we vary
the number of clusters from 2 to 64.

\begin{figure}
	\begin{center}
		\footnotesize
		\include{IM.vs.EM.stat}
		\caption{The relative external-memory performance of FlashMatrix for
			statistics computation on datasets with 65 million data points
			and the number of features varying from 8 to 512, normalized by
		its in-memory performance.}
		\label{perf:stat}
	\end{center}
\end{figure}

As the number of features in the datasets or the number of clusters increases,
the performance gap between in-memory and external-memory execution
narrows and eventually the external-memory performance gets almost 100\%
of in-memory performance (Figure \ref{perf:stat} and \ref{perf:clust}).
This observation conforms with the computation and I/O complexity of
the applications in Table \ref{tbl:algs}. When the number of features
in the dataset gets larger, computation in correlation and SVD grows more
rapidly than I/O and eventually CPU becomes
the bottleneck. Similarly, the computation of KMeans and GMM increases
more rapidly than I/O and get dominated by their CPU computation as the number
of clusters gets larger. Given the I/O throughput of 10 GB/s, it does not
require many features or clusters to have the applications bottlenecked by
CPU.

\begin{figure}
	\begin{center}
		\footnotesize
		\include{IM.vs.EM.clust}
		\caption{The relative external-memory performance of FlashMatrix for
			clustering algorithms with different numbers of clusters, normalized
		by its in-memory performance.}
		\label{perf:clust}
	\end{center}
\end{figure}

\subsection{Performance of FlashMatrix vs. Spark MLlib}

We further compare the performance of FlashMatrix implementations with the ones
in Spark MLlib \cite{mllib}. The FlashMatrix implementations of the applications
use the same algorithms used by Spark MLlib. For fair comparison, we runs the Spark
implementations with their native Scala interface and use a very large heap size
to ensure that all input data is cached in memory.

The applications in FlashMatrix significantly outperform Spark MLlib (Figure
\ref{perf:fm}). When the applications require more computation, the out-of-core
execution of FlashMatrix significantly outperforms Spark MLlib. Multivariant
statistical summary is the only application that does not outperform Spark when
being executed out of core because its out-of-core execution is bottlenecked
by I/O. For applications such as correlation and GMM, even though both FlashMatrix
and Spark implementations heavily rely on BLAS for matrix multiplication,
FlashMatrix can still significantly outperform Spark thanks to matrix operation
fusion and two-level partitioning to reduce data movement between memory and CPU.

\begin{figure}
	\begin{center}
		\footnotesize
		\include{FM.vs.spark}
		\caption{The performance of FlashMatrix both in memory and on SSDs
		compared with Spark.}
		\label{perf:fm}
	\end{center}
\end{figure}

\dz{TODO}
Array-oriented functional languages can consume a lot of memory. Here we show
that FlashMatrix actually doesn't consume much memory and the out-of-core
execution further reduce memory consumption.

\subsection{Performance of FlashMatrix vs. R}
In this section, we compare the performance of FlashMatrix with R on the matrix
with 65 million rows and 32 columns. To have a fair comparison, we run
FlashMatrix in a single thread. In addition, we measure the speedup of
FlashMatrix with multithreading. The R framework provides C implementations
for correlation, SVD and KMeans. The R package mclust \cite{mclust} provides
a FORTRAN implementation of GMM. We use R functions to compute statistic summary
except minimum and maximum because R does not provide an efficient way of
computing minimum and maximum of columns of a matrix.

\begin{figure}
	\begin{center}
		\footnotesize
		\include{FM.vs.R}
		\caption{The performance of FlashMatrix in a single thread both in memory
		and on SSDs compared with R.}
		\label{fig:fmR}
	\end{center}
\end{figure}

FlashMatrix significantly outperforms R even with a single thread in all of these
applications (Figure \ref{fig:fmR}). Even though the FlashMatrix implementation
of statistic summary computes more statistical values, it still outperforms
the R implementation by a factor of two, which indicates that FlashMatrix is
able to execute R code more efficiently than the R framework. The performance
result of the other applications indicates that the FlashMatrix can even
execute R code efficiently to outperform some C implementations.

\begin{figure}
	\begin{center}
		\footnotesize
		\include{speedup}
		\caption{The speedup of FlashMatrix with multithreading both in memory
		and on SSDs.}
		\label{fig:speedup}
	\end{center}
\end{figure}

FlashMatrix also speeds up the execution of all applications almost linearly
with more CPU cores (Figure \ref{fig:speedup}). The machine has only 48 CPU
cores, so running the applications with 64 threads does not double their
performance with 32 threads. Owing to operation fusion in CPU cache,
FlashMatrix significantly reduce data movement between CPU and main memory.
As such, memory bandwidth is the bottleneck for the applications and
the computation speeds up linearly with
more CPU cores. The performance results in Figure \ref{fig:fmR} and Figure
\ref{fig:speedup} indicate that the applications executed in FlashMatrix can
achieve performance comparable to or even outperform parallel C implementations.

\subsection{Effectiveness of optimizations}

In this section, we illustrate the effectiveness of our memory and CPU
optimizations in FlashMatrix. To reduce memory overhead, we focus on three
main optimizations: \textit{(i)} recycling memory chunks to reduce large
memory allocation, \textit{(ii)} matrix operation fusion in main
memory to reduce data movement between SSDs and main memory, \textit{(iii)}
matrix operation fusion in CPU cache to reduce data movement between main
memory and CPU cache. To reduce computation overhead, we illustrate
the effectiveness of using VUDF.
%Due to the space limit, we only illustrate the effectiveness of
%the optimizations on the applications when they are executed on SSDs.

Each memory optimization has significant performance improvement on most of
the applications when they are executed on SSDs (Figure \ref{perf:opts}).
Operation fusion in main memory achieves
the highest performance improvement in almost all applications, even in GMM,
which has the highest asymptotic computation complexity. Even though the SSDs
deliver 10GB/s I/O throughput, materializing every matrix operation separately
causes SSDs to be the main bottleneck in the system.
Fusing matrix operations in memory significantly reduces the burden on SSDs and
improves performance by a large factor. Operation fusion in the CPU cache also
has very positive performance impact in some applications even when
the applications run on SSDs. This suggests that with sufficient I/O optimizations,
many machine learning applications that run on fast SSDs can be bottlenecked by
the bandwidth of main memory, instead of I/O. Even though it is less noticeable,
reducing large memory allocation from Linux can significantly improvement I/O
performance and almost double the performance for all applications.

\begin{figure}
	\begin{center}
		\footnotesize
		\include{opts.EM}
		\caption{The effectiveness of memory optimizations on different
			applications when they are executed on SSDs. The three memory
		optimizations are applied to FlashMatrix incrementally.}
		\label{perf:opts}
	\end{center}
\end{figure}
