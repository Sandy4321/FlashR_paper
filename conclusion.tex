We present FlashR, a matrix-oriented programming framework that executes
R-programmed machine learning algorithms in parallel and out-of-core
automatically. FlashR scales to large datasets by utilizing commodity SSDs.

%For simplicity and generality, the core of FlashR only implements
%a small number of generalized matrix operators (GenOps). It reimplements
%many matrix operations in R \textit{base} package with GenOps to provide
%a familiar programming environment to users. To improve performance,
%FlashR uses vectorized element functions (VEleFuns) to reduce the
%overhead of function calls and fuses matrix operations to reduce data movement
%between CPU and SSDs.

Although R is considered to be slow and unable to scale to large datasets,
we demonstrate that with sufficient system-level optimizations, FlashR powers
the R programming interface to achieve high performance and scalability
for developing many machine learning algorithms. R implementations executed in FlashR
outperform H2O and Spark MLlib on all algorithms by a large factor, using
the same shared memory hardware. FlashR scales to datasets with billions of
data points easily with negligible amounts of memory and completes all
algorithms within a reasonable amount of time.

Even though SSDs are an order of magnitude slower than DRAM, the external-memory
execution of many algorithms in FlashR achieve performance approaching their in-memory
execution. We demonstrate that an I/O throughput of 10 GB/s saturates the CPU for many
algorithms, even in a large parallel NUMA machine. 
%As such, the external-memory execution also benefits from many in-memory optimizations.

FlashR simplifies the programming effort of writing parallel and out-of-core
implementations for large-scale machine learning. With FlashR, machine learning
researchers can prototype algorithms in a familiar programming environment,
while still getting efficient and scalable implementations.
We believe FlashR provides new opportunities for developing large-scale
machine learning algorithms.

%We should explore randomized algorithms to reduce computation complexity
%and/or I/O complexity to further accelerate machine learning algorithms
%in a single machine.
