Basic Linear Algebra Subprograms (BLAS) defines a small set of vector and
matrix operations for shared memory.. There exist a few
highly-optimized BLAS implementations, such as MKL \cite{mkl}, OpenBLAS
\cite{openblas}, GotoBLAS \cite{Goto} and ATLAS \cite{atlas}. 

Distributed-memory libraries \cite{trilinos, petsc, elemental}
scale to larger matrices. 
These build on BLAS and distribute computation with MPI.
They provide a limited set of predefined matrix operations and
require users to manually parallelize the remaining matrix operations.
%In contrast, FlashMatrix provides a few parallelized GenOps that 
%represent common data access patterns. 
%Each GenOp covers a large number of matrix operations.

%There are many distributed data processing frameworks.
MapReduce \cite{mapreduce} 
provides a single primitive that takes two user-defined functions. 
% RB not true
%written in low-level programming languages such as C/C++ and Java. 
For matrixes, MapReduce algorithms are inefficient, because they lack
primitives for matrix data access patterns.
Dryad \cite{dryad} and Naiad \cite{naiad} provide more primitives 
that support various data access patterns more efficiently.

Many frameworks that reduce programming complexity have been developed on top of distributed engines.
%Due to complexity of programming in the distributed execution engines, many
%programming frameworks have been developed on top of the distributed execution
%engines. 
Pig Latin \cite{pig} and FlumeJava \cite{flumejava}
provide high-level operations for general data analysis on Hadoop!
SystemML \cite{systemml} has a focus on machine learning. 
DryadLINQ \cite{dryadlinq} expresses data analysis tasks on Dryad. 
%Performance is determined by the underlying distributed execution engines.

The Spark \cite{spark} distributed, in-memory framework
provides a highly-optimized machine learning library (MLlib, \cite{mllib}).
Spark also provides an R programming interface called SparkR.  
We compare FlashMatrix with MLlib; Spark is the most efficient distributed engine.
%, which
%focuses on computation on data frames, a table-like data structure in R.
% DZTODO  what are data frames?

Efforts to parallelize array programming include
Revolution R \cite{rre} and Matlab's parallel computing toolbox, which
offer multicore parallelism and explicit distributed parallelism using MPI and MapReduce. 
Other works focus on implicit parallelization.
Presto \cite{presto} extends R to sparse matrix operations in distributed memory for graph
analysis. Ching et. al \cite{Ching12} parallelizes APL code by
compiling it to C. Accelerator \cite{accelerator} compiles
data-parallel operations on the fly to execute programs on a GPU.
