Basic Linear Algebra Subprograms (BLAS) defines a small set of vector and
matrix operations. There exist a few highly-optimized BLAS implementations,
such as MKL \cite{mkl} and ATLAS \cite{atlas}. 
Distributed libraries \cite{trilinos, petsc, elemental}
build on BLAS and distribute computation with MPI.
BLAS provides a limited set of matrix operations and requires
users to manually parallelize the remaining matrix operations.
%In contrast, FlashR provides a few parallelized GenOps that 
%represent common data access patterns. 
%Each GenOp covers a large number of matrix operations.

Recent works on out-of-core linear algebra \cite{Toledo99, Quintana-Orti12}
redesign algorithms to achieve efficient I/O access and reduce I/O
complexity. These works are orthogonal to our work and can be adopted.
Optimizing I/O
alone is insufficient. To achieve performance comparable to state-of-the-art
in-memory implementations, it is essential to move data efficiently in
the entire memory hierarchy.

MapReduce \cite{mapreduce} has been used for parallelizing machine learning
algorithms \cite{Chu06}. Even though MapReduce simplifies parallel programming,
it still requires low-level programming. As such, frameworks, such as Pig Latin
\cite{pig} and FlumeJava \cite{flumejava}, are built on top
of MapReduce to reduce programming complexity. MapReduce is inefficient for
matrix operations because
its I/O streaming primitives do not match matrix data access patterns.

Spark \cite{spark} is a distributed, in-memory framework that provides more
primitives for efficient computation and provides a distributed machine
learning library (MLlib \cite{mllib}). Although Spark is efficient, it usually
requires a large amount of RAM to process large datasets.

SystemML \cite{systemml, systemml2} develops an R-like scripting language for
machine learning on top of MapReduce and Spark. It deploys many optimizations,
such as data compression \cite{Elgohary16} and hybrid parallelization
\cite{Boehm14}. These optimizations are orthogonal with the ones in FlashR
and can be adopted.

Distributed machine learning frameworks have been developed to train machine
learning models on large datasets. For example, GraphLab \cite{graphlab}
formulates machine learning algorithms as graph computation; Petuum \cite{petuum}
is designed for machine learning algorithms with certain properties such as
error tolerance; TensorFlow \cite{tensorflow} trains machine learning models,
especially deep neural networks, with optimization algorithms such as
stochastic gradient descent.
%In contrast,
%FlashR aims at providing a simple programming interface for a wide variety
%of machine learning algorithms.

Efforts to parallelize array programming include Revolution R \cite{rro} and
Matlab's parallel computing toolbox, which offer multicore parallelism and
explicit distributed parallelism using MPI and MapReduce. Other works focus
on implicit parallelization. Presto \cite{presto} extends R to sparse matrix
operations in distributed memory for graph
analysis. Ching et. al \cite{Ching12} parallelize APL code by
compiling it to C. Accelerator \cite{accelerator} compiles
data-parallel operations on the fly to execute programs on a GPU.

OptiML \cite{optiml} is a domain-specific language for machine
learning in a heterogeneous computation environment such as multi-core
processors and GPU. It designs a new programming language and relies on
a compiler to generate code for the heterogenous environment.
