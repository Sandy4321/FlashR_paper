\documentclass[sigconf]{acmart}

\usepackage{booktabs} % For formal tables
\usepackage{epsfig,endnotes}
\usepackage{comment}
%\usepackage{subfigure}
\usepackage{url}
\usepackage{listings}
\usepackage{textcomp}
\usepackage{gnuplot-lua-tikz}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{minted}
\usepackage{bm}
\usepackage{paralist}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage{color,soul}
\usepackage{authblk}
\usepackage{multirow}
\usepackage{float}
%\usepackage[pdftex]{color}
\definecolor{lbcolor}{rgb}{0.9,0.9,0.9}

\newcommand{\dz}[1]{{\color{blue}{\it DZ: #1}}}
\newcommand{\rb}[1]{{\color{red}{\it RB: #1}}}

\newcommand{\para}[1]{\vspace{5pt}\noindent\textbf{{#1:}}}


% Copyright
%\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
\acmDOI{10.475/123_4}

% ISBN
\acmISBN{123-4567-24-567/08/06}

%Conference
\acmConference[KDD'17]{ACM conference}{August 2017}{Halifax, Nova Scotia,
Canada}
\acmYear{2017}
\copyrightyear{2017}

\acmPrice{}


\begin{document}
\title{FlashR: R-Programmed Parallel and Scalable Machine Learning using SSDs}
\titlenote{}
\subtitle{}
\subtitlenote{}


%\author{Da Zheng}
%\affiliation{%
%  \institution{Department of Computer Science \\ Johns Hopkins University}
%}
%\email{dzheng5@jhu.edu}

\author[1]{\rm Da Zheng}
\author[1]{\rm Disa Mhembere}
\author[3]{\rm Joshua T. Vogelstein}
\author[2]{\rm Carey E. Priebe}
\author[1]{\rm Randal Burns}
\affil[1]{Department of Computer Science, Johns Hopkins University}
\affil[2]{Department of Applied Mathematics and Statistics, Johns Hopkins University}
\affil[3]{Department of Biomedical Engineering, Johns Hopkins University}


\begin{abstract}
FlashR executes R code for machine learning and statistics 
in parallel and out-of-core automatically. It scales matrix operations
beyond memory capacity by utilizing solid-state drives (SSDs) in a non-uniform
memory architecture (NUMA). It provides a small number of generalized 
operations (GenOps) upon which we reimplement a large number of the
matrix functions in the R \textit{base} package. As such, FlashR can parallelize
and scale existing R code with little modification. To reduce data movement
between CPU and SSDs, FlashR evaluates matrix operations lazily, fuses
operations at runtime, and uses cache-aware, two-level matrix partitioning.
We evaluate FlashR on a variety of machine learning and statistics algorithms 
on inputs of up to four billion data points.
FlashR out-of-core tracks closely the performance of FlashR in-memory.
The R code for machine learning algorithms executed in FlashR
outperforms the in-memory execution of H2O and Spark MLlib by a large factor.
\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>10010520.10010553.10010562</concept_id>
  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010575.10010755</concept_id>
  <concept_desc>Computer systems organization~Redundancy</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010553.10010554</concept_id>
  <concept_desc>Computer systems organization~Robotics</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>10003033.10003083.10003095</concept_id>
  <concept_desc>Networks~Network reliability</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>  
\end{CCSXML}

%\ccsdesc[500]{Computer systems organization~Embedded systems}
%\ccsdesc[300]{Computer systems organization~Redundancy}
%\ccsdesc{Computer systems organization~Robotics}
%\ccsdesc[100]{Networks~Network reliability}

% We no longer use \terms command
%\terms{Theory}

\keywords{R programming, large-scale machine learning, SSDs}


\maketitle

\section{Introduction}
\input{intro}

\section{Related Work}
\input{relwork}

\input{design}

\input{eval}

\section{Conclusions}
\input{conclusion}

\bibliographystyle{ACM-Reference-Format}
\bibliography{kdd17} 

\end{document}
